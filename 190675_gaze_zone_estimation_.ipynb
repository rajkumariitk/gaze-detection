{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190675_gaze zone estimation .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Flatten,Dense, Dropout\n"
      ],
      "metadata": {
        "id": "lLUoI8ukgsLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Centerstack','Forward','Left_wing_mirror','Rearview_mirror','Right_wing_mirror']"
      ],
      "metadata": {
        "id": "nRr8oWLkDPjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_inv = {}\n",
        "\n",
        "for i in range(len(classes)):\n",
        "  map_inv[i] = classes[i]\n"
      ],
      "metadata": {
        "id": "hRz6WPGdDVNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_inv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8X7vKkDkD5",
        "outputId": "2ba69ddd-1364-4b08-8a1c-b655693c14a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Centerstack',\n",
              " 1: 'Forward',\n",
              " 2: 'Left_wing_mirror',\n",
              " 3: 'Rearview_mirror',\n",
              " 4: 'Right_wing_mirror'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Dataset/gaze_dataset/face'\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(data_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            )\n",
        "\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  batch_size=8)\n",
        "\n",
        "\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "normalized_ds = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "rdOIN-ns_xql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout((0.2)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  \n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(num_classes,activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpUQrFoKgLNQ",
        "outputId": "8fcae5e3-39e7-481a-db38-15a6172cf7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2415 files belonging to 5 classes.\n",
            "Found 2415 files belonging to 5 classes.\n",
            "Using 483 files for validation.\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 176s 2s/step - loss: 62.9818 - accuracy: 0.5180 - val_loss: 22.2307 - val_accuracy: 0.5342\n",
            "Epoch 2/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 37.4765 - accuracy: 0.6957 - val_loss: 32.4108 - val_accuracy: 0.5010\n",
            "Epoch 3/25\n",
            "76/76 [==============================] - 16s 211ms/step - loss: 27.6805 - accuracy: 0.7702 - val_loss: 28.7328 - val_accuracy: 0.6791\n",
            "Epoch 4/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 28.0516 - accuracy: 0.7714 - val_loss: 28.0397 - val_accuracy: 0.7184\n",
            "Epoch 5/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 18.4051 - accuracy: 0.8364 - val_loss: 26.2884 - val_accuracy: 0.7433\n",
            "Epoch 6/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 17.9496 - accuracy: 0.8464 - val_loss: 24.3156 - val_accuracy: 0.7992\n",
            "Epoch 7/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 12.5614 - accuracy: 0.8915 - val_loss: 14.0105 - val_accuracy: 0.8758\n",
            "Epoch 8/25\n",
            "76/76 [==============================] - 16s 208ms/step - loss: 13.4649 - accuracy: 0.8919 - val_loss: 30.7267 - val_accuracy: 0.8219\n",
            "Epoch 9/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 9.3308 - accuracy: 0.9064 - val_loss: 14.1005 - val_accuracy: 0.8882\n",
            "Epoch 10/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 9.0169 - accuracy: 0.9197 - val_loss: 16.5626 - val_accuracy: 0.8737\n",
            "Epoch 11/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 6.7921 - accuracy: 0.9317 - val_loss: 9.4529 - val_accuracy: 0.9420\n",
            "Epoch 12/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 6.5698 - accuracy: 0.9354 - val_loss: 5.2062 - val_accuracy: 0.9482\n",
            "Epoch 13/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 7.8184 - accuracy: 0.9333 - val_loss: 37.0013 - val_accuracy: 0.8344\n",
            "Epoch 14/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 6.4011 - accuracy: 0.9462 - val_loss: 7.0651 - val_accuracy: 0.9317\n",
            "Epoch 15/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 5.8920 - accuracy: 0.9536 - val_loss: 7.9691 - val_accuracy: 0.9400\n",
            "Epoch 16/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 5.1236 - accuracy: 0.9586 - val_loss: 9.3785 - val_accuracy: 0.9296\n",
            "Epoch 17/25\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 6.3156 - accuracy: 0.9453 - val_loss: 24.9136 - val_accuracy: 0.8737\n",
            "Epoch 18/25\n",
            "76/76 [==============================] - 16s 211ms/step - loss: 4.3435 - accuracy: 0.9598 - val_loss: 9.3047 - val_accuracy: 0.9172\n",
            "Epoch 19/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 3.1310 - accuracy: 0.9689 - val_loss: 7.4502 - val_accuracy: 0.9503\n",
            "Epoch 20/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 2.2595 - accuracy: 0.9714 - val_loss: 7.4342 - val_accuracy: 0.9358\n",
            "Epoch 21/25\n",
            "76/76 [==============================] - 16s 211ms/step - loss: 2.2658 - accuracy: 0.9735 - val_loss: 8.0811 - val_accuracy: 0.9441\n",
            "Epoch 22/25\n",
            "76/76 [==============================] - 16s 211ms/step - loss: 3.4571 - accuracy: 0.9652 - val_loss: 4.7325 - val_accuracy: 0.9524\n",
            "Epoch 23/25\n",
            "76/76 [==============================] - 16s 212ms/step - loss: 3.6076 - accuracy: 0.9665 - val_loss: 4.0763 - val_accuracy: 0.9689\n",
            "Epoch 24/25\n",
            "76/76 [==============================] - 16s 210ms/step - loss: 3.0483 - accuracy: 0.9743 - val_loss: 37.1323 - val_accuracy: 0.8737\n",
            "Epoch 25/25\n",
            "76/76 [==============================] - 16s 211ms/step - loss: 3.9495 - accuracy: 0.9660 - val_loss: 3.0231 - val_accuracy: 0.9772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe033092f10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test/1.jpg\"\n",
        "image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.array([input_arr])  \n",
        "predictions = model.predict(input_arr)"
      ],
      "metadata": {
        "id": "tkcNkUsskbOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mqm9GmCkm5j",
        "outputId": "6528adfe-a09a-4ffd-e5cd-7c7dd33c15d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2agZgM0kxa0",
        "outputId": "c7ebf736-31f7-4d28-ea5d-3648b71f03f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []"
      ],
      "metadata": {
        "id": "CXd5yZNiAUo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test\"\n",
        "\n",
        "for f in os.listdir(t):\n",
        "  i_path = os.path.join(t,f)\n",
        "\n",
        "  image_path = i_path\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr = np.array([input_arr])  \n",
        "  predictions = model.predict(input_arr)\n",
        "\n",
        "  y = f.split('.')\n",
        "\n",
        "  x = y[0]+'.'+y[1]\n",
        "  # print(x)\n",
        "  temp_dict['filename'].append(x)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  # dicti['class'].append(map_inv[np.argmax(predictions)])\n",
        "\n",
        "  x = np.argmax(predictions,axis = 1)\n",
        "  temp_dict['class'].append(map_inv[x[0]])\n"
      ],
      "metadata": {
        "id": "LdrlN4fdkJ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7BqDVzr3lLzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dict)"
      ],
      "metadata": {
        "id": "Hj_jP8hclJxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"jsr_final.csv\", index = False)"
      ],
      "metadata": {
        "id": "46n1VTkAlKX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRY-2\n"
      ],
      "metadata": {
        "id": "omF7uJjDnKSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "  \n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout((0.2)),\n",
        "\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout((0.2)),\n",
        "\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  # tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(num_classes,activation = 'softmax')\n",
        "])\n",
        "\n",
        "model2.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model2.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCzMXzrCnLzb",
        "outputId": "ce17e9ad-aaa4-450e-d3b9-23c78f86fd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2415 files belonging to 5 classes.\n",
            "Found 2415 files belonging to 5 classes.\n",
            "Using 483 files for validation.\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 35s 411ms/step - loss: 13.0071 - accuracy: 0.5296 - val_loss: 6.6889 - val_accuracy: 0.4327\n",
            "Epoch 2/25\n",
            "76/76 [==============================] - 29s 377ms/step - loss: 8.5950 - accuracy: 0.6882 - val_loss: 6.6294 - val_accuracy: 0.5424\n",
            "Epoch 3/25\n",
            "76/76 [==============================] - 29s 377ms/step - loss: 5.6312 - accuracy: 0.7747 - val_loss: 3.0162 - val_accuracy: 0.7619\n",
            "Epoch 4/25\n",
            "76/76 [==============================] - 29s 375ms/step - loss: 4.4066 - accuracy: 0.8290 - val_loss: 4.3827 - val_accuracy: 0.6812\n",
            "Epoch 5/25\n",
            "76/76 [==============================] - 29s 375ms/step - loss: 2.9663 - accuracy: 0.8613 - val_loss: 1.3984 - val_accuracy: 0.8841\n",
            "Epoch 6/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 1.6707 - accuracy: 0.9147 - val_loss: 1.4052 - val_accuracy: 0.8841\n",
            "Epoch 7/25\n",
            "76/76 [==============================] - 28s 375ms/step - loss: 1.6911 - accuracy: 0.9139 - val_loss: 2.5431 - val_accuracy: 0.8530\n",
            "Epoch 8/25\n",
            "76/76 [==============================] - 29s 375ms/step - loss: 1.1804 - accuracy: 0.9308 - val_loss: 1.1046 - val_accuracy: 0.9400\n",
            "Epoch 9/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 1.0436 - accuracy: 0.9408 - val_loss: 0.9357 - val_accuracy: 0.9358\n",
            "Epoch 10/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.7691 - accuracy: 0.9503 - val_loss: 0.4021 - val_accuracy: 0.9752\n",
            "Epoch 11/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.5179 - accuracy: 0.9706 - val_loss: 1.0062 - val_accuracy: 0.9545\n",
            "Epoch 12/25\n",
            "76/76 [==============================] - 29s 375ms/step - loss: 0.8732 - accuracy: 0.9631 - val_loss: 0.9878 - val_accuracy: 0.9441\n",
            "Epoch 13/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.8108 - accuracy: 0.9528 - val_loss: 0.7571 - val_accuracy: 0.9420\n",
            "Epoch 14/25\n",
            "76/76 [==============================] - 28s 375ms/step - loss: 0.8884 - accuracy: 0.9549 - val_loss: 1.1179 - val_accuracy: 0.9420\n",
            "Epoch 15/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.4475 - accuracy: 0.9731 - val_loss: 0.2992 - val_accuracy: 0.9752\n",
            "Epoch 16/25\n",
            "76/76 [==============================] - 28s 375ms/step - loss: 0.4716 - accuracy: 0.9743 - val_loss: 0.3130 - val_accuracy: 0.9710\n",
            "Epoch 17/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.4176 - accuracy: 0.9756 - val_loss: 0.8722 - val_accuracy: 0.9627\n",
            "Epoch 18/25\n",
            "76/76 [==============================] - 29s 374ms/step - loss: 0.5613 - accuracy: 0.9747 - val_loss: 0.6760 - val_accuracy: 0.9793\n",
            "Epoch 19/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.3660 - accuracy: 0.9801 - val_loss: 0.0959 - val_accuracy: 0.9814\n",
            "Epoch 20/25\n",
            "76/76 [==============================] - 29s 375ms/step - loss: 0.4085 - accuracy: 0.9781 - val_loss: 0.1662 - val_accuracy: 0.9876\n",
            "Epoch 21/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.2452 - accuracy: 0.9851 - val_loss: 0.0643 - val_accuracy: 0.9917\n",
            "Epoch 22/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.2716 - accuracy: 0.9855 - val_loss: 0.4561 - val_accuracy: 0.9752\n",
            "Epoch 23/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.1656 - accuracy: 0.9888 - val_loss: 0.1658 - val_accuracy: 0.9917\n",
            "Epoch 24/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.2980 - accuracy: 0.9822 - val_loss: 0.2667 - val_accuracy: 0.9938\n",
            "Epoch 25/25\n",
            "76/76 [==============================] - 28s 374ms/step - loss: 0.3670 - accuracy: 0.9818 - val_loss: 0.0247 - val_accuracy: 0.9979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe031bca410>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []"
      ],
      "metadata": {
        "id": "hlobFKWFBXJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test\"\n",
        "\n",
        "for f in os.listdir(t):\n",
        "  i_path = os.path.join(t,f)\n",
        "\n",
        "  image_path = i_path\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr = np.array([input_arr])  \n",
        "  predictions = model2.predict(input_arr)\n",
        "\n",
        "  y = f.split('.')\n",
        "\n",
        "  x = y[0]+'.'+y[1]\n",
        "  # print(x)\n",
        "  temp_dict['filename'].append(x)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  # dicti['class'].append(map_inv[np.argmax(predictions)])\n",
        "\n",
        "  x = np.argmax(predictions,axis = 1)\n",
        "\n",
        "  temp_dict['class'].append(map_inv[x[0]])"
      ],
      "metadata": {
        "id": "uP0Ec81Tqli3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dict)"
      ],
      "metadata": {
        "id": "em6P-gIQq2yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"jsr_jm_final1.csv\", index = False)"
      ],
      "metadata": {
        "id": "TbS_jex1rJEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try-3"
      ],
      "metadata": {
        "id": "BX6sfXpGryda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input"
      ],
      "metadata": {
        "id": "GTWY1nXcrvBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG19(input_shape=(256, 256, 3), weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "MBZt3CnXshKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "lUmd4nxFsyUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "x = Dropout(0.2)(x)\n",
        "# x = Dense(8,activation = \"relu\")(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "o9d24PeEs1iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model3.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGtlRWY8s2fu",
        "outputId": "75e998cd-d48d-4d71-8b18-2178ff45ccf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 42s 543ms/step - loss: 9.1495 - accuracy: 0.6323 - val_loss: 2.1325 - val_accuracy: 0.8758\n",
            "Epoch 2/15\n",
            "76/76 [==============================] - 41s 537ms/step - loss: 2.7067 - accuracy: 0.8625 - val_loss: 1.0150 - val_accuracy: 0.9400\n",
            "Epoch 3/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 2.1445 - accuracy: 0.9056 - val_loss: 1.2327 - val_accuracy: 0.9441\n",
            "Epoch 4/15\n",
            "76/76 [==============================] - 41s 539ms/step - loss: 1.1912 - accuracy: 0.9362 - val_loss: 0.9730 - val_accuracy: 0.9420\n",
            "Epoch 5/15\n",
            "76/76 [==============================] - 41s 541ms/step - loss: 0.8311 - accuracy: 0.9507 - val_loss: 0.1746 - val_accuracy: 0.9876\n",
            "Epoch 6/15\n",
            "76/76 [==============================] - 41s 537ms/step - loss: 0.8397 - accuracy: 0.9557 - val_loss: 0.5866 - val_accuracy: 0.9648\n",
            "Epoch 7/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.6114 - accuracy: 0.9636 - val_loss: 2.4285 - val_accuracy: 0.8861\n",
            "Epoch 8/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.9555 - accuracy: 0.9528 - val_loss: 0.7854 - val_accuracy: 0.9648\n",
            "Epoch 9/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.9792 - accuracy: 0.9594 - val_loss: 0.5521 - val_accuracy: 0.9710\n",
            "Epoch 10/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.4306 - accuracy: 0.9756 - val_loss: 0.1317 - val_accuracy: 0.9959\n",
            "Epoch 11/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.4705 - accuracy: 0.9781 - val_loss: 0.6767 - val_accuracy: 0.9565\n",
            "Epoch 12/15\n",
            "76/76 [==============================] - 41s 541ms/step - loss: 0.4565 - accuracy: 0.9768 - val_loss: 0.1270 - val_accuracy: 0.9876\n",
            "Epoch 13/15\n",
            "76/76 [==============================] - 41s 541ms/step - loss: 0.2954 - accuracy: 0.9797 - val_loss: 0.1379 - val_accuracy: 0.9917\n",
            "Epoch 14/15\n",
            "76/76 [==============================] - 41s 541ms/step - loss: 0.2598 - accuracy: 0.9834 - val_loss: 0.2023 - val_accuracy: 0.9814\n",
            "Epoch 15/15\n",
            "76/76 [==============================] - 41s 538ms/step - loss: 0.0744 - accuracy: 0.9917 - val_loss: 1.6427e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfb7f54850>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []"
      ],
      "metadata": {
        "id": "WQ3LocqhBt_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test\"\n",
        "\n",
        "for f in os.listdir(t):\n",
        "  i_path = os.path.join(t,f)\n",
        "\n",
        "  image_path = i_path\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr = np.array([input_arr])  \n",
        "  predictions = model3.predict(input_arr)\n",
        "\n",
        "  y = f.split('.')\n",
        "\n",
        "  x = y[0]+'.'+y[1]\n",
        "  # print(x)\n",
        "  temp_dict['filename'].append(x)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  # dicti['class'].append(map_inv[np.argmax(predictions)])\n",
        "\n",
        "  x = np.argmax(predictions,axis = 1)\n",
        "\n",
        "  temp_dict['class'].append(map_inv[x[0]])"
      ],
      "metadata": {
        "id": "qhVkJjQ1v3jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dict)"
      ],
      "metadata": {
        "id": "Pu_0s0iTv-af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"jsr_jm_final2.csv\", index = False)"
      ],
      "metadata": {
        "id": "eu8AXR5GwH-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try-4"
      ],
      "metadata": {
        "id": "Mp9b--mbxkfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input"
      ],
      "metadata": {
        "id": "OwCcLcEJxnQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG19(input_shape=(256, 256, 3), weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "rtngQ9TFxulE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "zll_UGgzxxWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "x = Dropout(0.3)(x)\n",
        "# x = Dense(8,activation = \"relu\")(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "V6CZsnJFyN0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model4.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNjuZ8SWyqbj",
        "outputId": "5ccaa39a-9120-446c-c9e0-2584d145cb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 42s 538ms/step - loss: 8.9295 - accuracy: 0.6211 - val_loss: 1.8864 - val_accuracy: 0.8675\n",
            "Epoch 2/16\n",
            "76/76 [==============================] - 41s 537ms/step - loss: 2.9296 - accuracy: 0.8398 - val_loss: 1.4865 - val_accuracy: 0.8986\n",
            "Epoch 3/16\n",
            "76/76 [==============================] - 41s 539ms/step - loss: 2.1188 - accuracy: 0.8886 - val_loss: 1.6415 - val_accuracy: 0.9089\n",
            "Epoch 4/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 1.7975 - accuracy: 0.9093 - val_loss: 0.9469 - val_accuracy: 0.9503\n",
            "Epoch 5/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 1.3630 - accuracy: 0.9371 - val_loss: 0.1270 - val_accuracy: 0.9814\n",
            "Epoch 6/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 1.2138 - accuracy: 0.9375 - val_loss: 0.5012 - val_accuracy: 0.9689\n",
            "Epoch 7/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.9745 - accuracy: 0.9478 - val_loss: 0.6770 - val_accuracy: 0.9503\n",
            "Epoch 8/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 1.1752 - accuracy: 0.9495 - val_loss: 0.5277 - val_accuracy: 0.9607\n",
            "Epoch 9/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.6665 - accuracy: 0.9652 - val_loss: 0.8631 - val_accuracy: 0.9545\n",
            "Epoch 10/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.5219 - accuracy: 0.9718 - val_loss: 0.1717 - val_accuracy: 0.9855\n",
            "Epoch 11/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.5990 - accuracy: 0.9710 - val_loss: 1.5610e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "76/76 [==============================] - 41s 539ms/step - loss: 0.3866 - accuracy: 0.9793 - val_loss: 0.3926 - val_accuracy: 0.9876\n",
            "Epoch 13/16\n",
            "76/76 [==============================] - 41s 541ms/step - loss: 0.3968 - accuracy: 0.9822 - val_loss: 0.1562 - val_accuracy: 0.9855\n",
            "Epoch 14/16\n",
            "76/76 [==============================] - 41s 539ms/step - loss: 0.4684 - accuracy: 0.9781 - val_loss: 0.5701 - val_accuracy: 0.9710\n",
            "Epoch 15/16\n",
            "76/76 [==============================] - 41s 539ms/step - loss: 0.6778 - accuracy: 0.9660 - val_loss: 0.3079 - val_accuracy: 0.9772\n",
            "Epoch 16/16\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 0.7075 - accuracy: 0.9677 - val_loss: 0.1194 - val_accuracy: 0.9896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf3d1be0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []"
      ],
      "metadata": {
        "id": "hLt8LvbUB9yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []\n",
        "\n",
        "t = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test\"\n",
        "\n",
        "for f in os.listdir(t):\n",
        "  i_path = os.path.join(t,f)\n",
        "\n",
        "  image_path = i_path\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr = np.array([input_arr])  \n",
        "  predictions = model4.predict(input_arr)\n",
        "\n",
        "  y = f.split('.')\n",
        "\n",
        "  x = y[0]+'.'+y[1]\n",
        "  # print(x)\n",
        "  temp_dict['filename'].append(x)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  # dicti['class'].append(map_inv[np.argmax(predictions)])\n",
        "\n",
        "  x = np.argmax(predictions,axis = 1)\n",
        "\n",
        "  temp_dict['class'].append(map_inv[x[0]])"
      ],
      "metadata": {
        "id": "BL91iiagy1yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dict)"
      ],
      "metadata": {
        "id": "-xnqUbIr2jla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"jsr_jm_final3.csv\", index = False)"
      ],
      "metadata": {
        "id": "XF1sxsUZ2ml9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try-5"
      ],
      "metadata": {
        "id": "wvDHPi0y3pld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_v2 = tf.keras.applications.resnet_v2.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=tf.keras.Input(shape=(256, 256, 3)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkTLgssd3ri-",
        "outputId": "63e707a7-23fa-4bab-84f9-525eb97c4650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "94683136/94668760 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet_v2.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "kbbt4nqW3sf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(resnet_v2.output)\n",
        "# x = Dropout(0.2)(x)\n",
        "# x = Dense(8,activation = \"relu\")(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model5 = Model(inputs=resnet_v2.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "ZzE0Rs6o37qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model5.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiI3BMpx4GDu",
        "outputId": "2db9cfd0-eac9-4555-931a-a656aa2b6783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 35s 392ms/step - loss: 806.2435 - accuracy: 0.3669 - val_loss: 161.0111 - val_accuracy: 0.5404\n",
            "Epoch 2/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 126.3006 - accuracy: 0.6058 - val_loss: 30.9394 - val_accuracy: 0.8012\n",
            "Epoch 3/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 161.6694 - accuracy: 0.6108 - val_loss: 125.4299 - val_accuracy: 0.6356\n",
            "Epoch 4/15\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 150.9069 - accuracy: 0.6596 - val_loss: 141.0475 - val_accuracy: 0.6377\n",
            "Epoch 5/15\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 134.0124 - accuracy: 0.6882 - val_loss: 28.1402 - val_accuracy: 0.8406\n",
            "Epoch 6/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 60.5521 - accuracy: 0.7805 - val_loss: 78.6070 - val_accuracy: 0.7329\n",
            "Epoch 7/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 94.6364 - accuracy: 0.7416 - val_loss: 55.8398 - val_accuracy: 0.8095\n",
            "Epoch 8/15\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 79.8678 - accuracy: 0.7660 - val_loss: 89.2604 - val_accuracy: 0.7288\n",
            "Epoch 9/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 98.2920 - accuracy: 0.7623 - val_loss: 71.2660 - val_accuracy: 0.8199\n",
            "Epoch 10/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 161.1734 - accuracy: 0.7130 - val_loss: 90.8978 - val_accuracy: 0.7598\n",
            "Epoch 11/15\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 158.5797 - accuracy: 0.7205 - val_loss: 143.1032 - val_accuracy: 0.7288\n",
            "Epoch 12/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 180.8649 - accuracy: 0.7267 - val_loss: 145.6260 - val_accuracy: 0.7453\n",
            "Epoch 13/15\n",
            "76/76 [==============================] - 21s 280ms/step - loss: 130.1819 - accuracy: 0.7781 - val_loss: 228.8183 - val_accuracy: 0.6936\n",
            "Epoch 14/15\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 61.9048 - accuracy: 0.8605 - val_loss: 45.1716 - val_accuracy: 0.8489\n",
            "Epoch 15/15\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 56.9795 - accuracy: 0.8580 - val_loss: 65.6443 - val_accuracy: 0.8551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0334743d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try-6"
      ],
      "metadata": {
        "id": "v1LD9a6CH_ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "LYLHAond4T_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resnet_v2.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "3scR-6W9IG2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "x = Dropout(0.2)(x)\n",
        "# x = Dense(8,activation = \"relu\")(x)\n",
        "# x = Dropout(0.1)(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model6 = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "cvXEpUZcIKaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model6.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGOk_OUnITyC",
        "outputId": "a47d9bd7-d618-4ef2-eca2-3f3716b4a99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 42s 542ms/step - loss: 9.3720 - accuracy: 0.6290 - val_loss: 2.7624 - val_accuracy: 0.8489\n",
            "Epoch 2/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 2.7251 - accuracy: 0.8518 - val_loss: 1.0321 - val_accuracy: 0.9337\n",
            "Epoch 3/15\n",
            "76/76 [==============================] - 41s 540ms/step - loss: 2.0511 - accuracy: 0.8981 - val_loss: 2.1046 - val_accuracy: 0.8778\n",
            "Epoch 4/15\n",
            "74/76 [============================>.] - ETA: 0s - loss: 1.4851 - accuracy: 0.9253"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = {}\n",
        "temp_dict['filename'] = []\n",
        "temp_dict['class'] = []\n",
        "\n",
        "t = \"/content/drive/MyDrive/Dataset/gaze_dataset/face_test\"\n",
        "\n",
        "for f in os.listdir(t):\n",
        "  i_path = os.path.join(t,f)\n",
        "\n",
        "  image_path = i_path\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path,target_size=(256,256))\n",
        "  input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr = np.array([input_arr])  \n",
        "  predictions = model6.predict(input_arr)\n",
        "\n",
        "  y = f.split('.')\n",
        "\n",
        "  x = y[0]+'.'+y[1]\n",
        "  # print(x)\n",
        "  temp_dict['filename'].append(x)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  # dicti['class'].append(map_inv[np.argmax(predictions)])\n",
        "\n",
        "  x = np.argmax(predictions,axis = 1)\n",
        "\n",
        "  temp_dict['class'].append(map_inv[x[0]])"
      ],
      "metadata": {
        "id": "Ov9GIX38JIf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dict)"
      ],
      "metadata": {
        "id": "JG_mIokSJOVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"jsr_jm_final6.csv\", index = False)"
      ],
      "metadata": {
        "id": "1L_ckKbZJUf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}